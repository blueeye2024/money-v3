# MCP 서버 활용 최적화 지침

## 🎯 목적
이 문서는 등록된 7개의 MCP 서버를 효과적으로 활용하여 개발 생산성을 극대화하는 방법을 제시합니다.

---

## 📋 MCP 서버 활용 전략

### 1️⃣ Context7 - 코드베이스 이해 및 문서화

#### 최적 활용 시나리오
- **새로운 기능 개발 전**: 관련 코드 검색 및 이해
- **버그 수정**: 문제가 있는 코드 위치 파악
- **리팩토링**: 중복 코드 및 개선 포인트 발견
- **문서 작성**: 자동 문서 생성

#### 효과적인 명령어 예시
```
✅ "signal_history 테이블을 사용하는 모든 함수를 찾아서 설명해줘"
✅ "KIS API 통합 부분의 코드를 분석하고 개선점을 제안해줘"
✅ "managed_stocks 테이블의 CRUD 작업을 수행하는 모든 함수를 나열해줘"
✅ "이 프로젝트의 전체 아키텍처를 설명해줘"

❌ "코드 보여줘" (너무 모호함)
❌ "뭔가 이상해" (구체적이지 않음)
```

#### 활용 팁
- 구체적인 테이블명, 함수명, 클래스명 사용
- "왜", "어떻게", "어디서" 같은 질문 활용
- 여러 파일에 걸친 로직 추적 시 유용

---

### 2️⃣ Sequential Thinking - 복잡한 문제 해결

#### 최적 활용 시나리오
- **복잡한 알고리즘 설계**: 매매 전략 로직 구현
- **시스템 설계**: 새로운 기능 아키텍처 설계
- **디버깅**: 복잡한 버그의 원인 분석
- **의사결정**: 여러 옵션 중 최선 선택

#### 효과적인 명령어 예시
```
✅ "SOXL 매수 신호 감지 로직을 단계별로 분석하고 개선 방안을 제시해줘"
✅ "실시간 가격 업데이트 시스템을 설계해줘. 단계별로 설명하고 각 단계의 장단점을 분석해줘"
✅ "데이터베이스 마이그레이션 계획을 수립해줘. 위험 요소와 대응 방안을 포함해서"
✅ "신호 중복 방지 로직의 문제점을 단계별로 분석해줘"

❌ "이거 어떻게 해?" (문제 정의 불명확)
❌ "빨리 해결해줘" (단계적 접근 불가)
```

#### 활용 팁
- "단계별로", "순서대로", "하나씩" 같은 키워드 사용
- 복잡한 문제는 작은 단위로 분해 요청
- 각 단계의 검증 방법도 함께 요청

---

### 3️⃣ Filesystem - 파일 및 코드 관리

#### 최적 활용 시나리오
- **파일 검색**: 특정 패턴의 파일 찾기
- **코드 수정**: 여러 파일 일괄 수정
- **설정 관리**: 환경 설정 파일 업데이트
- **로그 분석**: 로그 파일 읽기 및 분석

#### 효과적인 명령어 예시
```
✅ "backend 디렉토리에서 'signal'이 포함된 모든 Python 파일을 찾아줘"
✅ "db.py 파일에서 get_signals 함수를 수정해서 limit 기본값을 50으로 변경해줘"
✅ "모든 .env 파일을 찾아서 DATABASE_URL 설정을 확인해줘"
✅ "최근 수정된 파일 10개를 시간순으로 보여줘"

❌ "파일 좀 찾아줘" (어떤 파일인지 불명확)
❌ "다 고쳐줘" (범위가 너무 넓음)
```

#### 활용 팁
- 정확한 경로 지정: `/home/blue/blue/my_project/money/backend`
- 파일 확장자 명시: `.py`, `.json`, `.md`
- 백업 먼저 요청: "수정하기 전에 백업해줘"

---

### 4️⃣ MySQL - 데이터베이스 작업

#### 최적 활용 시나리오
- **데이터 조회**: 복잡한 쿼리 실행
- **통계 분석**: 매매 성과 분석
- **데이터 정리**: 오래된 데이터 삭제
- **스키마 관리**: 테이블 구조 확인 및 수정

#### 효과적인 명령어 예시
```
✅ "최근 30일간 SOXL의 매수 신호를 조회하고 평균 가격을 계산해줘"
✅ "signal_history 테이블에서 중복된 신호를 찾아서 제거해줘"
✅ "managed_stocks 테이블의 모든 종목의 현재가와 목표 비중을 조회해줘"
✅ "journal_transactions 테이블에서 FIFO 방식으로 각 종목의 평균 매수가를 계산해줘"

❌ "데이터 좀 봐줘" (어떤 데이터인지 불명확)
❌ "전부 삭제해줘" (위험한 작업)
```

#### 활용 팁
- 테이블명 정확히 명시
- 날짜 범위 지정: "최근 7일", "2026-01-01부터"
- 위험한 작업은 먼저 SELECT로 확인
- 트랜잭션 사용: "BEGIN; ... COMMIT;"

#### 주요 테이블 활용 가이드

**signal_history** - 신호 기록
```sql
-- 최근 신호 조회
SELECT * FROM signal_history 
WHERE ticker = 'SOXL' 
ORDER BY signal_time DESC 
LIMIT 10;

-- 신호 통계
SELECT ticker, signal_type, COUNT(*) as count
FROM signal_history
WHERE signal_time >= DATE_SUB(NOW(), INTERVAL 30 DAY)
GROUP BY ticker, signal_type;
```

**managed_stocks** - 관리 종목
```sql
-- 활성 종목 조회
SELECT ticker, name, current_price, target_ratio
FROM managed_stocks
WHERE is_active = TRUE
ORDER BY target_ratio DESC;

-- 가격 업데이트
UPDATE managed_stocks
SET current_price = 25.50, price_updated_at = NOW()
WHERE ticker = 'SOXL';
```

**journal_transactions** - 거래 내역
```sql
-- 종목별 수익률 계산
SELECT ticker, 
       SUM(CASE WHEN trade_type='BUY' THEN qty*price ELSE -qty*price END) as net_cost,
       SUM(CASE WHEN trade_type='BUY' THEN qty ELSE -qty END) as net_qty
FROM journal_transactions
GROUP BY ticker;
```

---

### 5️⃣ Shell - 시스템 작업 자동화

#### 최적 활용 시나리오
- **서버 관리**: 프로세스 시작/중지/재시작
- **배포**: 자동 배포 스크립트 실행
- **모니터링**: 시스템 상태 확인
- **백업**: 데이터베이스 및 파일 백업

#### 효과적인 명령어 예시
```
✅ "백엔드 서버를 재시작하고 로그를 확인해줘"
✅ "디스크 사용량을 확인하고 100GB 이상 사용 중인 디렉토리를 찾아줘"
✅ "데이터베이스를 백업하고 /backup 디렉토리에 저장해줘"
✅ "Python 가상환경을 활성화하고 requirements.txt의 패키지를 설치해줘"

❌ "서버 켜줘" (어떤 서버인지 불명확)
❌ "다 지워줘" (위험한 작업)
```

#### 활용 팁
- 위험한 명령어는 먼저 dry-run 요청
- 백그라운드 실행: `nohup ... &`
- 로그 확인: `tail -f /var/log/...`
- 권한 확인: `sudo` 필요 여부 명시

---

### 6️⃣ Memory - 컨텍스트 관리

#### 최적 활용 시나리오
- **프로젝트 요구사항 저장**: 장기 기억
- **대화 컨텍스트 유지**: 이전 논의 참조
- **지식 베이스 구축**: 프로젝트 관련 지식 축적
- **TODO 관리**: 작업 목록 추적

#### 효과적인 명령어 예시
```
✅ "SOXL 매매 전략의 핵심 규칙을 기억해줘: 30분봉 골든크로스 + 박스권 10% 돌파"
✅ "이전에 논의한 신호 중복 방지 로직을 다시 설명해줘"
✅ "프로젝트의 주요 개선 사항 목록을 저장해줘"
✅ "지난주에 논의한 데이터베이스 최적화 방안을 상기시켜줘"

❌ "기억해" (무엇을 기억할지 불명확)
❌ "전에 뭐라고 했지?" (구체적이지 않음)
```

#### 활용 팁
- 중요한 결정사항은 명시적으로 저장 요청
- 태그 사용: "매매전략", "버그수정", "개선사항"
- 정기적으로 저장된 내용 리뷰 요청

---

### 7️⃣ Fetch - 외부 데이터 수집

#### 최적 활용 시나리오
- **주가 데이터**: 실시간 시세 조회
- **API 테스트**: 외부 API 호출 테스트
- **웹 스크래핑**: 필요한 데이터 수집
- **문서 다운로드**: 외부 문서 가져오기

#### 효과적인 명령어 예시
```
✅ "Yahoo Finance API로 SOXL의 현재가를 가져와줘"
✅ "KIS API를 호출해서 IONQ의 30분봉 데이터를 조회해줘"
✅ "https://example.com/api/stock/TSLA 에서 데이터를 가져와서 파싱해줘"
✅ "Investing.com에서 UPRO의 최근 뉴스를 스크래핑해줘"

❌ "데이터 가져와줘" (어디서, 무엇을)
❌ "API 호출해줘" (어떤 API, 어떤 엔드포인트)
```

#### 활용 팁
- API 키 필요 여부 확인
- Rate limit 고려
- 에러 처리 요청
- 데이터 검증 요청

---

## 🔄 MCP 서버 조합 활용 전략

### 시나리오 1: 새로운 기능 개발
```
1. Context7: 관련 코드 검색 및 이해
   "signal_history 테이블 관련 모든 함수를 찾아줘"

2. Sequential Thinking: 기능 설계
   "신호 필터링 기능을 단계별로 설계해줘"

3. Filesystem: 코드 작성
   "backend/filters.py 파일을 생성하고 필터 함수를 구현해줘"

4. MySQL: 데이터 검증
   "새로운 필터가 올바르게 작동하는지 테스트 쿼리를 실행해줘"

5. Memory: 결과 저장
   "이번에 구현한 필터링 로직의 핵심 내용을 기억해줘"
```

### 시나리오 2: 버그 수정
```
1. MySQL: 문제 데이터 확인
   "중복된 신호가 있는지 확인해줘"

2. Context7: 관련 코드 찾기
   "신호 저장 로직을 찾아서 분석해줘"

3. Sequential Thinking: 원인 분석
   "중복 신호가 발생하는 원인을 단계별로 분석해줘"

4. Filesystem: 코드 수정
   "db.py의 save_signal 함수를 수정해서 중복 체크를 추가해줘"

5. Shell: 테스트
   "백엔드를 재시작하고 테스트를 실행해줘"
```

### 시나리오 3: 데이터 분석
```
1. MySQL: 데이터 추출
   "최근 3개월간의 모든 매매 신호를 조회해줘"

2. Sequential Thinking: 분석 계획
   "매매 성과를 분석하는 방법을 단계별로 제시해줘"

3. MySQL: 통계 계산
   "종목별 승률과 평균 수익률을 계산해줘"

4. Filesystem: 결과 저장
   "분석 결과를 analysis_report.md 파일로 저장해줘"

5. Memory: 인사이트 저장
   "분석에서 발견한 주요 인사이트를 기억해줘"
```

### 시나리오 4: 시스템 배포
```
1. Shell: 현재 상태 확인
   "실행 중인 프로세스와 포트 사용 현황을 확인해줘"

2. Filesystem: 설정 파일 업데이트
   "production.env 파일을 업데이트해줘"

3. MySQL: 데이터베이스 백업
   "데이터베이스를 백업해줘"

4. Shell: 배포 실행
   "deploy.sh 스크립트를 실행하고 로그를 모니터링해줘"

5. Fetch: 헬스 체크
   "배포된 서버의 헬스 체크 엔드포인트를 호출해줘"
```

---

## 💡 효과적인 명령어 작성 원칙

### 1. 구체성 (Specificity)
```
❌ "코드 수정해줘"
✅ "backend/db.py의 get_signals 함수에서 limit 파라미터 기본값을 30에서 50으로 변경해줘"
```

### 2. 컨텍스트 (Context)
```
❌ "이거 고쳐줘"
✅ "signal_history 테이블에 중복 데이터가 저장되는 문제가 있어. save_signal 함수를 수정해서 중복 체크를 추가해줘"
```

### 3. 목표 명시 (Goal)
```
❌ "데이터 좀 봐줘"
✅ "최근 7일간 SOXL의 매수 신호를 조회해서 평균 진입 가격을 계산하고, 현재가와 비교해줘"
```

### 4. 제약 조건 (Constraints)
```
❌ "파일 삭제해줘"
✅ "30일 이상 된 로그 파일만 삭제해줘. 단, 먼저 삭제될 파일 목록을 보여주고 확인받아줘"
```

### 5. 검증 요청 (Validation)
```
❌ "배포해줘"
✅ "배포 전에 테스트를 실행하고, 모든 테스트가 통과하면 배포해줘. 배포 후 헬스 체크도 확인해줘"
```

---

## 🎯 작업 유형별 최적 MCP 조합

### 코드 개발
- **주요**: Context7, Filesystem, Sequential Thinking
- **보조**: Memory, MySQL

### 데이터 분석
- **주요**: MySQL, Sequential Thinking
- **보조**: Filesystem, Memory

### 시스템 운영
- **주요**: Shell, MySQL, Filesystem
- **보조**: Fetch, Memory

### 디버깅
- **주요**: Context7, MySQL, Sequential Thinking
- **보조**: Filesystem, Shell

### 문서화
- **주요**: Context7, Memory, Filesystem
- **보조**: Sequential Thinking

---

## ⚡ 생산성 향상 팁

### 1. 템플릿 활용
자주 사용하는 명령어는 템플릿으로 저장:
```bash
# ~/.bash_aliases에 추가
alias mcp-signal-check="echo '최근 24시간 신호를 조회하고 중복 여부를 확인해줘'"
alias mcp-db-backup="echo '데이터베이스를 백업하고 /backup 디렉토리에 저장해줘'"
alias mcp-server-status="echo '백엔드 서버 상태를 확인하고 CPU/메모리 사용률을 보여줘'"
```

### 2. 일괄 작업
여러 작업을 한 번에 요청:
```
"다음 작업을 순서대로 수행해줘:
1. 데이터베이스에서 최근 신호 조회
2. 중복 신호 제거
3. 결과를 report.md로 저장
4. 백엔드 서버 재시작"
```

### 3. 조건부 실행
조건을 명시하여 안전하게 실행:
```
"signal_history 테이블에 중복 데이터가 있으면 제거해줘. 
단, 제거하기 전에 백업을 만들고, 제거될 레코드 수를 먼저 알려줘"
```

### 4. 결과 검증
항상 결과 검증 요청:
```
"managed_stocks 테이블의 current_price를 업데이트하고, 
업데이트된 레코드 수와 변경 전후 값을 보여줘"
```

---

## 🚫 피해야 할 패턴

### 1. 모호한 요청
```
❌ "뭔가 이상해"
❌ "고쳐줘"
❌ "확인해줘"
```

### 2. 과도한 권한 요청
```
❌ "모든 데이터 삭제해줘"
❌ "시스템 전체를 재설정해줘"
```

### 3. 컨텍스트 없는 질문
```
❌ "이거 왜 안돼?"
❌ "에러 나는데?"
```

### 4. 한 번에 너무 많은 작업
```
❌ "프로젝트 전체를 리팩토링하고 새 기능 10개 추가하고 배포까지 해줘"
```

---

## 📈 성과 측정

### MCP 활용 효과 측정 지표
1. **개발 속도**: 기능 구현 시간 단축
2. **코드 품질**: 버그 감소, 코드 리뷰 통과율
3. **운영 효율**: 장애 대응 시간, 배포 빈도
4. **지식 축적**: 문서화 수준, 팀 지식 공유

### 주간 리뷰 체크리스트
- [ ] MCP를 활용한 주요 작업 목록
- [ ] 가장 유용했던 MCP 서버
- [ ] 개선이 필요한 워크플로우
- [ ] 새로 발견한 활용 방법

---

## 🔄 지속적 개선

### 1. 피드백 수집
- 어떤 명령어가 효과적이었는지 기록
- 실패한 요청의 원인 분석
- 개선 아이디어 문서화

### 2. 워크플로우 최적화
- 반복 작업 자동화
- 자주 사용하는 조합 템플릿화
- 팀과 베스트 프랙티스 공유

### 3. 새로운 활용법 탐색
- MCP 서버 업데이트 확인
- 새로운 기능 테스트
- 다른 프로젝트 적용 사례 학습

---

**작성일**: 2026-01-04  
**작성자**: Antigravity AI Agent  
**버전**: 1.0  
**다음 업데이트**: 사용 경험 축적 후
